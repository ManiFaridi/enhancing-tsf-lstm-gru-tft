{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":95981,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":80509,"modelId":104926}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yfinance -q","metadata":{"_cell_guid":"70c67c54-9495-4b2a-9407-3286eae2ad89","_uuid":"231768a3-8821-4cdb-9cbb-8c6d039c1134","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport yfinance as yf\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential, Model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Concatenate, Attention, Conv1D, MaxPooling1D, Flatten\nfrom tensorflow.keras import Model, regularizers","metadata":{"_cell_guid":"4f3c9278-9c44-4da6-93fc-983917139b22","_uuid":"e2ed6ca0-59a0-476e-b633-15a4353d7c11","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    # Calculate RSI\n    def calc_rsi(close, period):\n        deltas = close.diff()\n        gains = deltas.clip(lower=0)\n        losses = -deltas.clip(upper=0)\n        avg_gain = gains.rolling(window=period, min_periods=1).mean()\n        avg_loss = losses.rolling(window=period, min_periods=1).mean()\n        rs = avg_gain / avg_loss\n        rsi = 100 - (100 / (rs + 1))\n        return rsi\n\n    # Calculate OBV\n    def calc_obv(df):\n        obv = ((df['Close'] > df['Close'].shift(1)) * 2 - 1) * df['Volume']\n        return obv.cumsum()\n\n    # Calculate MACD\n    def calc_macd(df):\n        ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n        ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n        macd = ema12 - ema26\n        macd_signal = macd.ewm(span=9, adjust=False).mean()\n        macd_histogram = macd - macd_signal\n        return macd, macd_signal, macd_histogram\n\n    # Calculate ATR\n    def calculate_atr(df, period=3):\n        high_low = df['High'] - df['Low']\n        high_previous_close = np.abs(df['High'] - df['Close'].shift(1))\n        low_previous_close = np.abs(df['Low'] - df['Close'].shift(1))\n        true_range = pd.DataFrame({\n            'High-Low': high_low, \n            'High-PreviousClose': high_previous_close, \n            'Low-PreviousClose': low_previous_close\n        })\n        tr = true_range.max(axis=1)\n        atr = tr.rolling(window=period, min_periods=1).mean()\n        return atr\n\n    # Add technical indicators\n    def add_technicals(df):\n        df['MA5'] = df['Close'].rolling(5).mean()\n        df['MA10'] = df['Close'].rolling(10).mean()\n        df['RSI'] = calc_rsi(df['Close'], period=14)\n        df['OBV'] = calc_obv(df)\n        df['MACD'], df['MACD Signal'], df['MACD Histogram'] = calc_macd(df)\n        df['ATR'] = calculate_atr(df)\n        return df\n\n    # Remove 'Adj Close' if present\n    df = add_technicals(df)\n    df = df.drop(columns=['Adj Close', 'Volume'], errors='ignore')\n\n    # Create Target columns for the next day's prices\n    df['Target1'] = df['Close'].shift(-1)\n    df['Target2'] = df['Close'].shift(-2)\n    df['Target3'] = df['Close'].shift(-3)\n\n    return df.dropna()\ndf = yf.download('SPY', progress=False)\ndf = preprocess(df)","metadata":{"_cell_guid":"780c4fe8-c761-4dd5-9ad0-594cf40b04ab","_uuid":"2176dee4-909e-4eba-bfac-58ac763075bf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the features and target\nscalers = {}\ntarget_columns = ['Target1', 'Target2', 'Target3']\nfeature_columns = list(df.columns)\nfor i in target_columns:\n    feature_columns.remove(i)\nprint(feature_columns)\nfor col in feature_columns:\n    scaler = StandardScaler()\n    df[col] = scaler.fit_transform(df[[col]])\n    scalers[col] = scaler\n\n# Scale the target column separately\ntarget_scaler = StandardScaler()\ndf['Target1'] = target_scaler.fit_transform(df[['Target1']])\nscalers['Target1'] = target_scaler\ntarget_scaler = StandardScaler()\ndf['Target2'] = target_scaler.fit_transform(df[['Target2']])\nscalers['Target2'] = target_scaler\ntarget_scaler = StandardScaler()\ndf['Target3'] = target_scaler.fit_transform(df[['Target3']])\nscalers['Target3'] = target_scaler","metadata":{"_cell_guid":"896c5668-8ad7-4d0f-a2f1-7586e19df467","_uuid":"2a269a9b-9e93-4cdf-b34b-80fd91e26b0a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sequencer(df, sl):\n    xs, ys = [], []\n    num_rows = len(df)\n    for i in range(0, num_rows - sl + 1):\n        chunk = df.iloc[i:i + sl]\n        nchunk = df.iloc[i+1:i+sl+1]\n        features = chunk.drop(target_columns, axis=1).values\n        target = nchunk[target_columns].values[0]\n        xs.append(features)\n        ys.append(target)\n    return np.array(xs), np.array(ys)\n\n# Create sequences\nsequence_length = 15\nX_sequences, y_sequences = sequencer(df, sequence_length)\n\nprint(f'X_sequences shape: {X_sequences.shape}')\nprint(f'y_sequences shape: {y_sequences.shape}')","metadata":{"_cell_guid":"3a91510c-ac5a-4627-96ce-b010b693eab5","_uuid":"42c28e31-5033-467b-8026-4afd416d84e8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training, validation, and test sets\nX_train, X_temp, y_train, y_temp = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)","metadata":{"_cell_guid":"8529cc17-af5f-44aa-8f22-5fb2438ab154","_uuid":"8690b585-621b-4d5e-bb66-683e8a4ad610","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Concatenate, Attention, Conv1D, MaxPooling1D, Flatten, TimeDistributed\nfrom tensorflow.keras import Model, regularizers\n\ndef build_model(sequence_length=15, num_features=12):\n    inputs = Input(shape=(sequence_length, num_features))\n\n    conv = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(inputs)\n    pool = MaxPooling1D(pool_size=2)(conv)\n    flat = Flatten()(pool)\n\n    lstm_out = LSTM(32, return_sequences=True)(inputs)\n\n    gru_out = GRU(32, return_sequences=True)(inputs)\n\n    attention = Attention()([lstm_out, gru_out])\n\n    attention_flat = Flatten()(attention)\n\n    dense_lstm = Dense(16, activation='relu')(lstm_out)\n    dense_gru = Dense(16, activation='relu')(gru_out)\n\n    dense_lstm_flat = Flatten()(dense_lstm)\n    dense_gru_flat = Flatten()(dense_gru)\n\n    concat = Concatenate()([flat, attention_flat, dense_lstm_flat, dense_gru_flat])\n\n    outputs = Dense(3, activation='linear')(concat)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse', metrics=['mape'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"_cell_guid":"47b20d82-970d-42f3-8ba6-f90d1e86e893","_uuid":"e71b52ce-b934-40cb-b3d1-6c204687c6fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(\n    model,\n    to_file='model.png',\n    dpi=2400,\n    show_shapes=True,\n    show_layer_activations=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mcb = [\n    tf.keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min'),\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=100, min_delta=1e-5),\n]\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    epochs=500,\n    batch_size=8,\n    callbacks=mcb,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation loss\nplt.plot(history.history['val_loss'], color='green', label='val_loss')\nplt.plot(history.history['loss'], color='blue', label='loss')\nplt.grid()\nplt.legend()\nplt.show()\n\n# Plot training & validation MAPE\nplt.plot(history.history['val_mape'], color='green', label='val_mape')\nplt.plot(history.history['mape'], color='blue', label='mape')\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"_cell_guid":"2e1488e7-d957-4812-afdc-0d808bb29ba7","_uuid":"fb7a7fae-7763-47e0-8368-aab28d100680","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nmodel = keras.saving.load_model('best_model.keras')","metadata":{"_cell_guid":"0a939120-516d-4ccd-ad1e-e7409c65f028","_uuid":"70f58621-dcb5-4914-ae1d-e8772b86d79b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"_cell_guid":"b017f533-af5b-44bc-b123-9d8f079e0fdd","_uuid":"6c63b5ec-8ffd-4430-88e7-ee43ae14ac5c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"43a02b47-63d5-4461-9b36-72183ee69a8f","_uuid":"9acf7c24-6e89-4784-80ca-c2c97fec2abb"},"execution_count":null,"outputs":[]}]}